# Data Denormalization:

Data denormalization is introducing some redundancy into previously normalized databases to optimize database query performance. It introduces some pre-computed redundancy using different techniques to solve issues in normalized data. 

## Why Need for Denormalization??

- Improve user experience through enhanced query performance
- Reduce complexity, keep the data model simple
- Enhance application scalability
- Generate data reports faster


## Thinngs to Keep eye on while useing Denormalization 
- The most obvious disadvantage is __increased data redundancy__.
- There can be __inconsistencies between data sets__. For example, consider mirrored databases. It requires taking replications, which need to be synced to make them up-to-date.  Inconsistencies can arise if there is a failure in the replica. 
Techniques like data splitting and mirrored tables will require additional storage space, which can be costly.
- Denormalization also __increases the complexity of the data schema__. It will be harder to maintain the data store as the number of tables increases.
- Inserts and Updates will be __costly__.
- Maintenance costs can be high due to the increased complexity and redundancy of the data. 


## These techniques include:
- Table splitting
- Adding derived and redundant columns
- Mirrored tables
